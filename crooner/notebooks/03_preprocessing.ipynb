{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "1. [Summary](#section1)\n",
    "2. [Tokenization](#section2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary <a name=\"section1\"></a>\n",
    "In this notebook I will load in the cleaned dataset and prepare the song lyrics for modeling. Steps in this process will include splitting the full lyrics string into individual words, creating input / output sequences, tokenizing the words, and converting the target feature from integer tokens to categorical one-hot vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json, time, re, string, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%run ../assets/sql_cred.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the file labeling helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = '../assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[0-z]+_[0-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Saved at: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the cleaned lyric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = pd.read_csv('../assets/1549918191_lyric_df.csv', index_col='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_df = lyric_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>clean_lyrics</th>\n",
       "      <th>rep_ratio</th>\n",
       "      <th>total_words_track</th>\n",
       "      <th>unique_words_track</th>\n",
       "      <th>mean_len_words_track</th>\n",
       "      <th>total_lines_track</th>\n",
       "      <th>unique_lines_track</th>\n",
       "      <th>mean_words_line</th>\n",
       "      <th>mean_unique_words_line</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0h7TlF8gKb61aSm874s3cV</th>\n",
       "      <td>\\n\\nIf your needle is near\\nNeedle is near\\nYo...</td>\n",
       "      <td>if your needle is near \\n needle is near \\n yo...</td>\n",
       "      <td>0.65</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>3.7</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6koowTu9pFHPEcZnACLKbK</th>\n",
       "      <td>\\n\\n[Verse 1]\\nBrown skin girl on the other si...</td>\n",
       "      <td>brown skin girl on the other side of the room ...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>132</td>\n",
       "      <td>52</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1JkhKUXAoNivi87ipmV3rp</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIt's simple, I love it\\nHaving ...</td>\n",
       "      <td>its simple i love it \\n having you near me hav...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>151</td>\n",
       "      <td>63</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51lPx6ZCSalL2kvSrDUyJc</th>\n",
       "      <td>\\n\\n[Intro: Whistling]\\n\\n[Verse 1]\\nA great b...</td>\n",
       "      <td>a great big bang and dinosaurs \\n fiery rainin...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>126</td>\n",
       "      <td>76</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3vqlZUIT3rEmLaYKDBfb4Q</th>\n",
       "      <td>\\n\\n[Verse 1]\\nIsn't she lovely\\nIsn't she won...</td>\n",
       "      <td>isnt she lovely \\n isnt she wonderful \\n isnt ...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>108</td>\n",
       "      <td>66</td>\n",
       "      <td>4.1</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   lyrics  \\\n",
       "track_id                                                                    \n",
       "0h7TlF8gKb61aSm874s3cV  \\n\\nIf your needle is near\\nNeedle is near\\nYo...   \n",
       "6koowTu9pFHPEcZnACLKbK  \\n\\n[Verse 1]\\nBrown skin girl on the other si...   \n",
       "1JkhKUXAoNivi87ipmV3rp  \\n\\n[Verse 1]\\nIt's simple, I love it\\nHaving ...   \n",
       "51lPx6ZCSalL2kvSrDUyJc  \\n\\n[Intro: Whistling]\\n\\n[Verse 1]\\nA great b...   \n",
       "3vqlZUIT3rEmLaYKDBfb4Q  \\n\\n[Verse 1]\\nIsn't she lovely\\nIsn't she won...   \n",
       "\n",
       "                                                             clean_lyrics  \\\n",
       "track_id                                                                    \n",
       "0h7TlF8gKb61aSm874s3cV  if your needle is near \\n needle is near \\n yo...   \n",
       "6koowTu9pFHPEcZnACLKbK  brown skin girl on the other side of the room ...   \n",
       "1JkhKUXAoNivi87ipmV3rp  its simple i love it \\n having you near me hav...   \n",
       "51lPx6ZCSalL2kvSrDUyJc  a great big bang and dinosaurs \\n fiery rainin...   \n",
       "3vqlZUIT3rEmLaYKDBfb4Q  isnt she lovely \\n isnt she wonderful \\n isnt ...   \n",
       "\n",
       "                        rep_ratio  total_words_track  unique_words_track  \\\n",
       "track_id                                                                   \n",
       "0h7TlF8gKb61aSm874s3cV       0.65                 57                  20   \n",
       "6koowTu9pFHPEcZnACLKbK       0.61                132                  52   \n",
       "1JkhKUXAoNivi87ipmV3rp       0.58                151                  63   \n",
       "51lPx6ZCSalL2kvSrDUyJc       0.40                126                  76   \n",
       "3vqlZUIT3rEmLaYKDBfb4Q       0.39                108                  66   \n",
       "\n",
       "                        mean_len_words_track  total_lines_track  \\\n",
       "track_id                                                          \n",
       "0h7TlF8gKb61aSm874s3cV                   3.7                 14   \n",
       "6koowTu9pFHPEcZnACLKbK                   4.1                 24   \n",
       "1JkhKUXAoNivi87ipmV3rp                   4.2                 29   \n",
       "51lPx6ZCSalL2kvSrDUyJc                   4.0                 20   \n",
       "3vqlZUIT3rEmLaYKDBfb4Q                   4.1                 21   \n",
       "\n",
       "                        unique_lines_track  mean_words_line  \\\n",
       "track_id                                                      \n",
       "0h7TlF8gKb61aSm874s3cV                   8              5.9   \n",
       "6koowTu9pFHPEcZnACLKbK                  13              7.4   \n",
       "1JkhKUXAoNivi87ipmV3rp                  21              7.1   \n",
       "51lPx6ZCSalL2kvSrDUyJc                  18              8.2   \n",
       "3vqlZUIT3rEmLaYKDBfb4Q                  20              7.0   \n",
       "\n",
       "                        mean_unique_words_line  \n",
       "track_id                                        \n",
       "0h7TlF8gKb61aSm874s3cV                     5.1  \n",
       "6koowTu9pFHPEcZnACLKbK                     5.8  \n",
       "1JkhKUXAoNivi87ipmV3rp                     5.8  \n",
       "51lPx6ZCSalL2kvSrDUyJc                     7.2  \n",
       "3vqlZUIT3rEmLaYKDBfb4Q                     6.1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the summary statistics for the data before preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_words_track</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>282.639528</td>\n",
       "      <td>125.380335</td>\n",
       "      <td>13.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>1339.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_words_track</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>96.058956</td>\n",
       "      <td>37.770647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_len_words_track</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>3.748175</td>\n",
       "      <td>0.264051</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_lines_track</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>40.800674</td>\n",
       "      <td>17.889364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_lines_track</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>27.646828</td>\n",
       "      <td>12.112090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_words_line</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>9.069175</td>\n",
       "      <td>2.031524</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>55.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_unique_words_line</th>\n",
       "      <td>1781.0</td>\n",
       "      <td>7.585345</td>\n",
       "      <td>1.677593</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count        mean         std   min    25%    50%  \\\n",
       "total_words_track       1781.0  282.639528  125.380335  13.0  195.0  267.0   \n",
       "unique_words_track      1781.0   96.058956   37.770647   5.0   74.0   92.0   \n",
       "mean_len_words_track    1781.0    3.748175    0.264051   2.8    3.6    3.7   \n",
       "total_lines_track       1781.0   40.800674   17.889364   1.0   28.0   38.0   \n",
       "unique_lines_track      1781.0   27.646828   12.112090   1.0   20.0   25.0   \n",
       "mean_words_line         1781.0    9.069175    2.031524   4.2    7.9    8.8   \n",
       "mean_unique_words_line  1781.0    7.585345    1.677593   3.6    6.6    7.4   \n",
       "\n",
       "                          75%     max  \n",
       "total_words_track       346.0  1339.0  \n",
       "unique_words_track      112.0   433.0  \n",
       "mean_len_words_track      3.9     5.7  \n",
       "total_lines_track        51.0   224.0  \n",
       "unique_lines_track       33.0   189.0  \n",
       "mean_words_line           9.9    55.4  \n",
       "mean_unique_words_line    8.3    39.8  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to iterate through the dataset and perform the desired preprocessing steps. Since I intend to use word-level predictions for my model, I will split the lyrics into individual words and tokenize based on the resulting vocabulary. I will utilize a sliding window format to create input / output sets where a input sequence will be used to predict the next word following that sequence. The sliding window will then move forward one word and the process will be repeated until a document of our desired length is produced. In the context of preprocessing, I will create these sequences for each track prior to tokenizing. Once the tokenizer is trained on the complete corpus, it will be saved out to be used for tokenizing our input text for the model to predict on. The resulting split, sequenced, and tokenized input set will be reshaped corresponding to the shape required for the model input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization <a name=\"section2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_lyrics(\n",
    "    df=lyric_df,\n",
    "    lyrics_col=['clean_lyrics'],\n",
    "    seq_len=4, \n",
    "    output_len=1,\n",
    "    save_dir='../assets'):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    print('Processing lyrics...')\n",
    "    for _, track in df[lyrics_col].iterrows():\n",
    "        lyrics = track[0]\n",
    "        lyrics_spaced = re.sub(r'( +)', ' ', lyrics)\n",
    "        lyrics_split = lyrics_spaced.split(' ')\n",
    "        corpus.extend(lyrics_split)\n",
    "\n",
    "        for i in range(len(lyrics_split) - seq_len):\n",
    "                X.append(np.array(lyrics_split[i:i + seq_len]))\n",
    "                y.extend(np.array(lyrics_split[i + seq_len:i + seq_len + output_len]))\n",
    "\n",
    "    print('Fitting Tokenizer...')\n",
    "    tokenizer = Tokenizer(oov_token=0)\n",
    "    tokenizer.filters = tokenizer.filters.replace('\\n', '')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    print(f'Vocab size = {vocab_size}')\n",
    "    \n",
    "    formatted_name, now, file_description= filename_format_log(f'{save_dir}/LSTM315_300tokenizer.pkl')\n",
    "\n",
    "    with open(formatted_name, 'wb+') as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    print(f'Tokenizer saved to {formatted_name}.')          \n",
    "\n",
    "    print('Indexing sequences...')\n",
    "    X_indexed = [[tokenizer.texts_to_sequences([word])[0] for word in row] for row in X]\n",
    "    y_indexed = [tokenizer.texts_to_sequences([word])[0] for word in y]\n",
    "\n",
    "    print('Reshaping and converting to Categorical...')\n",
    "    X_reshape = np.reshape(X_indexed, (len(X_indexed), seq_len))\n",
    "    \n",
    "    formatted_name, now, file_description= filename_format_log(f'{save_dir}/LSTM315_300Xreshape.npy')\n",
    "    np.save(formatted_name, X_reshape)\n",
    "        \n",
    "    y_cat = to_categorical(y_indexed)\n",
    "    \n",
    "    formatted_name, now, file_description= filename_format_log(f'{save_dir}/LSTM315_300ycat.npz')\n",
    "    y_cat_coo = coo_matrix(y_cat)\n",
    "    sparse.save_npz(formatted_name, y_cat_coo)\n",
    "    \n",
    "    print(f'Lyrics successfully tokenized, sequenced, indexed, and saved out to {save_dir}.') \n",
    "    \n",
    "    return X_reshape, y_cat, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing lyrics...\n",
      "Fitting Tokenizer...\n",
      "Vocab size = 12335\n",
      "Tokenizer saved to ../assets/1549597149_LSTM315_300tokenizer.pkl.\n",
      "Indexing sequences...\n",
      "Reshaping and converting to Categorical...\n",
      "Lyrics successfully tokenized, sequenced, indexed, and saved out to ../assets.\n"
     ]
    }
   ],
   "source": [
    "X_reshape, y_cat, vocab_size = tokenize_lyrics(\n",
    "    df=lyric_df,\n",
    "    lyrics_col=['clean_lyrics'],\n",
    "    seq_len=4, \n",
    "    output_len=1,\n",
    "    save_dir='../assets'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE TO NOTEBOOK 04a: MODELING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
