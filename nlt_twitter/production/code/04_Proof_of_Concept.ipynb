{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "-  [Configure Postgres Server with Docker](#Configure-Postgres-Server-with-Docker)\n",
    "-  [Application Token](#Application-Token)\n",
    "-  [Collect Tweets](#Collect-Tweets)\n",
    "-  [Retrieve Data from PostgreSQL Database](#Retrieve-Data-from-PostgreSQL-Database)\n",
    "-  [Clean Text](#Clean-Text)\n",
    "-  [Model Prep](#Model-Prep)\n",
    "-  [Logistic Regression Classification](#Logistic-Regression-Classification)\n",
    "-  [Save Data](#Save-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter, json, time, re, nltk, pickle\n",
    "\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "from psycopg2.extras import RealDictCursor, Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../assets/sql_test.py\n",
    "%run ../assets/twitter_credentials.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Postgres Server with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to programmatically connect to and insert data into database:\n",
    "-  **con_cur_to_db**: returns both a connection and a cursor object for database\n",
    "-  **execute_query**: executes query directly to database, without having to create a cursor and connection each time\n",
    "-  **insert_entry_json**: inserts data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    con = pg2.connect(host=IP_ADDRESS,\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection\n",
    "\n",
    "def insert_entry_json(data, tablename=None):\n",
    "    con, cur = con_cur_to_db()\n",
    "    for x in data:\n",
    "        cur.execute(f'INSERT INTO {tablename} (data) VALUES ({Json(x)});')\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table `raw_tweets` to save our collected data into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = '''CREATE TABLE raw_tweets\n",
    "(id SERIAL,\n",
    "data JSONB);'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "execute_query(query, command=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define API keys and instantiate twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {\n",
    "    'consumer_key':        CONSUMER_KEY,\n",
    "    'consumer_secret':     CONSUMER_SECRET,\n",
    "    'access_token_key':    ACCESS_TOKEN,\n",
    "    'access_token_secret': ACCESS_TOKEN_SECRET\n",
    "}\n",
    "\n",
    "api = twitter.Api(consumer_key         =   twitter_keys['consumer_key'],\n",
    "                  consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "                  access_token_key     =   twitter_keys['access_token_key'],\n",
    "                  access_token_secret  =   twitter_keys['access_token_secret'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect tweets and store into database:\n",
    "-  `term`: term to search by\n",
    "-  `geocode`: specify geolocation within which to search for tweets\n",
    "-  `since`: search for tweets since specified date\n",
    "-  `count`: number of results returned (100 max)\n",
    "-  `sql_db`: database to save tweets to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamTweets(term, geocode, since, count, sql_db):\n",
    "    for i in range(1,8):\n",
    "        year, month, day = since.split('-')\n",
    "        day = int(day)\n",
    "        day-=1\n",
    "        day = str(day).zfill(2)\n",
    "        date = year + month + day\n",
    "        after = datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        results = api.GetSearch(\n",
    "            term = term,\n",
    "            geocode = geocode,\n",
    "            return_json = True\n",
    "        )\n",
    "\n",
    "        insert_entry_json(data = results['statuses'], \n",
    "                          tablename = sql_db)\n",
    "        before = after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to have `streamTweets` on a loop to programmatically collect tweets:\n",
    "-  Repeat function 15 times, returning 100 (`count`) each time\n",
    "-  Pause for 40 seconds to avoid exceeding rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_repeater(term, geocode, since, sql_db, repeats=15, count=100):\n",
    "    for i in range(repeats):\n",
    "        since = since\n",
    "        \n",
    "        streamTweets(term, geocode, since, count, sql_db)\n",
    "        print(f'Loop {i+1} complete. Raw tweets pushed to {sql_db}.')\n",
    "        time.sleep(40)\n",
    "        \n",
    "    print('All tweets pulled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect most recent tweets:\n",
    "-  that contains the term `storm` (terms were determined by natural disasters during time of search)\n",
    "-  within 15 mile radius of location\n",
    "-  starting from 2019-01-13\n",
    "-  run function 100 times, collecting 700 tweets (1 week x 100 tweets) each time\n",
    "-  save into `raw_tweets` database\n",
    "-  sample output is displayed \n",
    "\n",
    "We searched over two locations and used the following terms for each:\n",
    "\n",
    "|Location|Latitude|Longitude|Search Terms|Since Date|\n",
    "|---|---|---|---|---|\n",
    "|Malibu, CA|34.0249999|-118.773830238|flood, mudslide, landslide, rain, storm|2019-01-06|\n",
    "|Riverside, CA|33.9806|-117.3755|flood|2019-01-13|"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tweet_repeater(term='storm',\n",
    "               geocode='33.9806,-117.3755,15mi',\n",
    "               since='2019-01-13',\n",
    "               repeats=100, \n",
    "               count=100,\n",
    "               sql_db='raw_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from PostgreSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT * to determine data structure and find information most relevant to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query = '''SELECT * FROM raw_tweets;'''\n",
    "response = execute_query(query, dict_cur=True)\n",
    "print(type(response))\n",
    "print(type(response[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text (Tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is stored as a list of nested dictionaries. We want to retrieve the text itself (`text`), nested under `data` and put it in a dataframe (`df_text`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'text'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "df_text = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo-Coordinates\n",
    "We then want to retrieve the geo coordinates for each tweet in order to map their location and allocate resources there. This is stored in dataframe `df_geo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ?column?\n",
       "89   [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "190  [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "191  [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "192  [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "193  [[[-118.668404, 33.704538], [-118.155409, 33.7..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"SELECT data#>'{place,bounding_box,coordinates}'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "df_geo = pd.DataFrame(response).dropna()\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users that do not have location enabled will return `NaN`, so we'll drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bounding box for the geo-fence is in a nested list. We key into the list and take the average left/right latitude and upper/lower longitude to approximate the location of a given tweet. These values are stored in the `lat` and `long` column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "\n",
    "for tweet in df_geo['?column?']:\n",
    "    inside = tweet[0][1]\n",
    "    outside = tweet[0][3]\n",
    "    lat = (inside[0] + outside[0])/2\n",
    "    long = (inside[1] + outside[1])/2\n",
    "    latitude.append(lat)\n",
    "    longitude.append(long)\n",
    "    \n",
    "df_geo['lat'] = latitude\n",
    "df_geo['long'] = longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the `lat` and `long` columns were correctly added to df_geo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ?column?         lat       long\n",
       "89   [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "190  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "191  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "192  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789\n",
       "193  [[[-118.668404, 33.704538], [-118.155409, 33.7... -118.411907  34.020789"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32490, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then drop the nested list stored in `?column?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.drop(columns=['?column?'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge our text and geo-coordinates data into one dataframe, `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_text, df_geo, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every twitter query returns a random subset of tweets containing the specified search term. We drop duplicates to ensure every tweet is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the merged dataframe to ensure the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ENCINO UPDATE: LAFD @PIOErikScott says evacuat...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>@darreng60 👍🙏☺️</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ?column?         lat       long\n",
       "89   ENCINO UPDATE: LAFD @PIOErikScott says evacuat... -118.411907  34.020789\n",
       "191  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789\n",
       "193  Fire crews keeping an eye on hillside that hav... -118.411907  34.020789\n",
       "194  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789\n",
       "579                                    @darreng60 👍🙏☺️ -118.411907  34.020789"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the `?column?` column to prepare for text cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'?column?':'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',tweet)\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    tweet = re.sub('@', '', tweet)\n",
    "    tweet = re.sub('rt', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = [processTweet(i) for i in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df['processed'].map(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['tokenized'].map(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ENCINO UPDATE: LAFD @PIOErikScott says evacuat...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>encino update: lafd pioerikscott says evacuati...</td>\n",
       "      <td>[encino, update, lafd, pioerikscott, says, eva...</td>\n",
       "      <td>encino update lafd pioerikscott say evacuation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>[twdandmetal, axis7173, nearly_depaed, unknown...</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>[fire, crews, keeping, an, eye, on, hillside, ...</td>\n",
       "      <td>fire crew keeping an eye on hillside that have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>[twdandmetal, axis7173, nearly_depaed, unknown...</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>@darreng60 👍🙏☺️</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>darreng60 👍🙏☺️</td>\n",
       "      <td>[darreng60]</td>\n",
       "      <td>darreng60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text         lat       long  \\\n",
       "89   ENCINO UPDATE: LAFD @PIOErikScott says evacuat... -118.411907  34.020789   \n",
       "191  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789   \n",
       "193  Fire crews keeping an eye on hillside that hav... -118.411907  34.020789   \n",
       "194  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789   \n",
       "579                                    @darreng60 👍🙏☺️ -118.411907  34.020789   \n",
       "\n",
       "                                             processed  \\\n",
       "89   encino update: lafd pioerikscott says evacuati...   \n",
       "191  twdandmetal axis7173 nearly_depaed unknown_meu...   \n",
       "193  fire crews keeping an eye on hillside that hav...   \n",
       "194  twdandmetal axis7173 nearly_depaed unknown_meu...   \n",
       "579                                     darreng60 👍🙏☺️   \n",
       "\n",
       "                                             tokenized  \\\n",
       "89   [encino, update, lafd, pioerikscott, says, eva...   \n",
       "191  [twdandmetal, axis7173, nearly_depaed, unknown...   \n",
       "193  [fire, crews, keeping, an, eye, on, hillside, ...   \n",
       "194  [twdandmetal, axis7173, nearly_depaed, unknown...   \n",
       "579                                        [darreng60]   \n",
       "\n",
       "                                            lemmatized  \n",
       "89   encino update lafd pioerikscott say evacuation...  \n",
       "191  twdandmetal axis7173 nearly_depaed unknown_meu...  \n",
       "193  fire crew keeping an eye on hillside that have...  \n",
       "194  twdandmetal axis7173 nearly_depaed unknown_meu...  \n",
       "579                                          darreng60  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are primarily interested in tweets related to flooding, we will TF-IDF vectorize these samples with the TF-IDF vectorizer fit on the training data from the combined flood datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./assets/tfidf_flood.pkl', 'rb') as f:\n",
    "    tfidf_flood = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./assets/tfidf_flood_col.pkl', 'rb') as f:\n",
    "    cols = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>1800</th>\n",
       "      <th>...</th>\n",
       "      <th>yycflood</th>\n",
       "      <th>yycflood abflood</th>\n",
       "      <th>yycflood relief</th>\n",
       "      <th>yycflood yyc</th>\n",
       "      <th>yycflood yychelps</th>\n",
       "      <th>yycfloods</th>\n",
       "      <th>yychelps</th>\n",
       "      <th>yychelps yycflood</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1060 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   10  100   11   12   13        14   15  1800 ...   yycflood  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.446169  0.0   0.0 ...        0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0 ...        0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0 ...        0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0 ...        0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  0.0   0.0 ...        0.0   \n",
       "\n",
       "   yycflood abflood  yycflood relief  yycflood yyc  yycflood yychelps  \\\n",
       "0               0.0              0.0           0.0                0.0   \n",
       "1               0.0              0.0           0.0                0.0   \n",
       "2               0.0              0.0           0.0                0.0   \n",
       "3               0.0              0.0           0.0                0.0   \n",
       "4               0.0              0.0           0.0                0.0   \n",
       "\n",
       "   yycfloods  yychelps  yychelps yycflood  zone  zoo  \n",
       "0        0.0       0.0                0.0   0.0  0.0  \n",
       "1        0.0       0.0                0.0   0.0  0.0  \n",
       "2        0.0       0.0                0.0   0.0  0.0  \n",
       "3        0.0       0.0                0.0   0.0  0.0  \n",
       "4        0.0       0.0                0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 1060 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = tfidf_flood.transform(df['lemmatized'])\n",
    "tfidf_df = pd.DataFrame(tfidf_df.toarray(), columns=cols)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the trained Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'assets/lr_flood.pkl', 'rb') as f:\n",
    "    lr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting classes for the unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the predicted classes back into the dataframe so we can reference the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>processed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label_on-topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ENCINO UPDATE: LAFD @PIOErikScott says evacuat...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>encino update: lafd pioerikscott says evacuati...</td>\n",
       "      <td>[encino, update, lafd, pioerikscott, says, eva...</td>\n",
       "      <td>encino update lafd pioerikscott say evacuation...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>[twdandmetal, axis7173, nearly_depaed, unknown...</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>fire crews keeping an eye on hillside that hav...</td>\n",
       "      <td>[fire, crews, keeping, an, eye, on, hillside, ...</td>\n",
       "      <td>fire crew keeping an eye on hillside that have...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>@twdandmetal @Axis7173 @nearly_departed @unkno...</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>[twdandmetal, axis7173, nearly_depaed, unknown...</td>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>@darreng60 👍🙏☺️</td>\n",
       "      <td>-118.411907</td>\n",
       "      <td>34.020789</td>\n",
       "      <td>darreng60 👍🙏☺️</td>\n",
       "      <td>[darreng60]</td>\n",
       "      <td>darreng60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text         lat       long  \\\n",
       "89   ENCINO UPDATE: LAFD @PIOErikScott says evacuat... -118.411907  34.020789   \n",
       "191  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789   \n",
       "193  Fire crews keeping an eye on hillside that hav... -118.411907  34.020789   \n",
       "194  @twdandmetal @Axis7173 @nearly_departed @unkno... -118.411907  34.020789   \n",
       "579                                    @darreng60 👍🙏☺️ -118.411907  34.020789   \n",
       "\n",
       "                                             processed  \\\n",
       "89   encino update: lafd pioerikscott says evacuati...   \n",
       "191  twdandmetal axis7173 nearly_depaed unknown_meu...   \n",
       "193  fire crews keeping an eye on hillside that hav...   \n",
       "194  twdandmetal axis7173 nearly_depaed unknown_meu...   \n",
       "579                                     darreng60 👍🙏☺️   \n",
       "\n",
       "                                             tokenized  \\\n",
       "89   [encino, update, lafd, pioerikscott, says, eva...   \n",
       "191  [twdandmetal, axis7173, nearly_depaed, unknown...   \n",
       "193  [fire, crews, keeping, an, eye, on, hillside, ...   \n",
       "194  [twdandmetal, axis7173, nearly_depaed, unknown...   \n",
       "579                                        [darreng60]   \n",
       "\n",
       "                                            lemmatized label_on-topic  \n",
       "89   encino update lafd pioerikscott say evacuation...          False  \n",
       "191  twdandmetal axis7173 nearly_depaed unknown_meu...          False  \n",
       "193  fire crew keeping an eye on hillside that have...          False  \n",
       "194  twdandmetal axis7173 nearly_depaed unknown_meu...          False  \n",
       "579                                          darreng60          False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_on-topic'] = preds\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of samples assigned to each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    896\n",
       "True      21\n",
       "Name: label_on-topic, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_on-topic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the tweets collected are off topic, a result we would expect given there currently is no state of emergency. Sampling 10 tweets from each class to see representative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label_on-topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64052</th>\n",
       "      <td>devondstewa don t sta with me logically it doe...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166766</th>\n",
       "      <td>honestly uber pool wouldn t be a thing if ther...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122410</th>\n",
       "      <td>we really got 7 sub at our school like what s ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29834</th>\n",
       "      <td>the way these clipper fan is booing j30_randle...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19753</th>\n",
       "      <td>kaydontplay_ girl it s your year all about you...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50763</th>\n",
       "      <td>this is why the medium asks absurd question so...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86063</th>\n",
       "      <td>hey bed</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57757</th>\n",
       "      <td>manilaluzon</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16499</th>\n",
       "      <td>thatssocute we are aren t we beau</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17221</th>\n",
       "      <td>they have slowly added in culture under the wh...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lemmatized label_on-topic\n",
       "64052   devondstewa don t sta with me logically it doe...          False\n",
       "166766  honestly uber pool wouldn t be a thing if ther...          False\n",
       "122410  we really got 7 sub at our school like what s ...          False\n",
       "29834   the way these clipper fan is booing j30_randle...          False\n",
       "19753   kaydontplay_ girl it s your year all about you...          False\n",
       "50763   this is why the medium asks absurd question so...          False\n",
       "86063                                             hey bed          False\n",
       "57757                                         manilaluzon          False\n",
       "16499                   thatssocute we are aren t we beau          False\n",
       "17221   they have slowly added in culture under the wh...          False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label_on-topic'] == 'False'][['lemmatized', 'label_on-topic']].sample(n=10, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets classified as false appear to be correctly labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label_on-topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155326</th>\n",
       "      <td>damien flood crest 2017 oil on canvas 30 x 24 ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>heathdwilliams lol triple storm front rolling ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145488</th>\n",
       "      <td>malibu storm prep video foxnews bethannstyne n...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27986</th>\n",
       "      <td>at citymalibu council meeting city manager rev...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>little man think it s going to flood whenever ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9184</th>\n",
       "      <td>awoodruff the massive mannasas molasses flood</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>am i crazy to drive into malibu during a rain ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130927</th>\n",
       "      <td>los angeles ca tue jan 15th am forecast today ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13826</th>\n",
       "      <td>a an adult driving through paially flooded str...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147075</th>\n",
       "      <td>nike adapt bb sneaker the first shoe of 2019 t...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lemmatized label_on-topic\n",
       "155326  damien flood crest 2017 oil on canvas 30 x 24 ...           True\n",
       "9187    heathdwilliams lol triple storm front rolling ...           True\n",
       "145488  malibu storm prep video foxnews bethannstyne n...           True\n",
       "27986   at citymalibu council meeting city manager rev...           True\n",
       "7532    little man think it s going to flood whenever ...           True\n",
       "9184        awoodruff the massive mannasas molasses flood           True\n",
       "7301    am i crazy to drive into malibu during a rain ...           True\n",
       "130927  los angeles ca tue jan 15th am forecast today ...           True\n",
       "13826   a an adult driving through paially flooded str...           True\n",
       "147075  nike adapt bb sneaker the first shoe of 2019 t...           True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label_on-topic'] == 'True'][['lemmatized', 'label_on-topic']].sample(n=10, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets labeled as on-topic appear to have relavance to a potential weather event. Words such as flood, storm, rain, accident, and safety align with terms identified by our modeling pipeline. We will look at the tweets that a high and low certainty of being labeled by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62675569, 0.37324431],\n",
       "       [0.99175131, 0.00824869],\n",
       "       [0.55118037, 0.44881963],\n",
       "       ...,\n",
       "       [0.97606998, 0.02393002],\n",
       "       [0.99631707, 0.00368293],\n",
       "       [0.99175131, 0.00824869]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba = lr.predict_proba(tfidf_df)\n",
    "proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the class prediction probabilities for each sample. Below, we will assign them into high certainty and low certainty groups so we can review the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_cert = []\n",
    "low_cert = []\n",
    "\n",
    "for i, prob in enumerate(proba):\n",
    "    if (prob[0] > .75) | (prob[0] < .25):\n",
    "        high_cert.append(i)\n",
    "    \n",
    "    elif (prob[0] > .40) & (prob[0] < .60):\n",
    "        low_cert.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label_on-topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>fire crew keeping an eye on hillside that have...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7320</th>\n",
       "      <td>that s more like it theandykatz stjohnsbball t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7322</th>\n",
       "      <td>good chance of some thunderstorm high wind and...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>little man think it s going to flood whenever ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9187</th>\n",
       "      <td>heathdwilliams lol triple storm front rolling ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25462</th>\n",
       "      <td>area of malibu will be under mandatory evacuat...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28258</th>\n",
       "      <td>mandatory evacuation b c of mudslide debris fl...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35108</th>\n",
       "      <td>2011 2019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119932</th>\n",
       "      <td>help u fight eating disorder here by donating ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lemmatized label_on-topic\n",
       "193     fire crew keeping an eye on hillside that have...          False\n",
       "7320    that s more like it theandykatz stjohnsbball t...          False\n",
       "7322    good chance of some thunderstorm high wind and...          False\n",
       "7532    little man think it s going to flood whenever ...           True\n",
       "9187    heathdwilliams lol triple storm front rolling ...           True\n",
       "25462   area of malibu will be under mandatory evacuat...          False\n",
       "28258   mandatory evacuation b c of mudslide debris fl...          False\n",
       "35108                                           2011 2019          False\n",
       "119932  help u fight eating disorder here by donating ...          False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[low_cert, [5,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low certainty texts appear to be mixed accuracy, with tweets such as 7322, 25462 & 28258 incorrectly labeled. Interestingly, the term 'evacuation' appeared in 2 of the incorrectly labeled tweets, which suggests room for improvement with our model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>label_on-topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>twdandmetal axis7173 nearly_depaed unknown_meu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>darreng60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>i m planning on playing how to survive in sout...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>witch hunt la tonight 1 15 8pm aaannnd we re b...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>dooooyouuuubooo espn go run in traffic</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>okay this pose is becoming a problem i need to...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>ponglizardo gillette that s not what i took aw...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>nevergillette</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2450</th>\n",
       "      <td>michaelfinleyl1 zeromc we re riding rain or sh...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>faed on a twenty call it gas money</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>content lipstick woman photooftheday photograp...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>showtimetate</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>rain or shine these educator mean business tea...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>mcloudy sky calling for rain lol</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>i thought it wa gonna rain all day so i didn t...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>how come at least where i live when it s raini...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>xoshirls</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>kindness is free love is free love this photo ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>taylorsierraa you right lmao i just can t beli...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             lemmatized label_on-topic\n",
       "191   twdandmetal axis7173 nearly_depaed unknown_meu...          False\n",
       "194   twdandmetal axis7173 nearly_depaed unknown_meu...          False\n",
       "579                                           darreng60          False\n",
       "700   i m planning on playing how to survive in sout...          False\n",
       "977   witch hunt la tonight 1 15 8pm aaannnd we re b...          False\n",
       "1597             dooooyouuuubooo espn go run in traffic          False\n",
       "2001  okay this pose is becoming a problem i need to...          False\n",
       "2004  ponglizardo gillette that s not what i took aw...          False\n",
       "2193                                      nevergillette          False\n",
       "2450  michaelfinleyl1 zeromc we re riding rain or sh...          False\n",
       "2479                 faed on a twenty call it gas money          False\n",
       "2480  content lipstick woman photooftheday photograp...          False\n",
       "2499                                       showtimetate          False\n",
       "2873  rain or shine these educator mean business tea...          False\n",
       "2876                   mcloudy sky calling for rain lol          False\n",
       "2877  i thought it wa gonna rain all day so i didn t...          False\n",
       "2878  how come at least where i live when it s raini...          False\n",
       "3061                                           xoshirls          False\n",
       "3195  kindness is free love is free love this photo ...          False\n",
       "3519  taylorsierraa you right lmao i just can t beli...          False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[high_cert, [5,6]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high certainty tweets have mention of weather-related data but are correctly labeled off-topic, suggesting our model performs well when judging the context of certain terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed_tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
