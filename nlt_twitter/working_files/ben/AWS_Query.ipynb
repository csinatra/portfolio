{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter in /Applications/anaconda3/lib/python3.6/site-packages (3.5)\n",
      "Requirement already satisfied: future in /Applications/anaconda3/lib/python3.6/site-packages (from python-twitter) (0.17.1)\n",
      "Requirement already satisfied: requests-oauthlib in /Applications/anaconda3/lib/python3.6/site-packages (from python-twitter) (1.0.0)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/lib/python3.6/site-packages (from python-twitter) (2.21.0)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /Applications/anaconda3/lib/python3.6/site-packages (from requests-oauthlib->python-twitter) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (2018.11.29)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Applications/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Applications/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Applications/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /Applications/anaconda3/lib/python3.6/site-packages (2.7.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import json\n",
    "import time\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from psycopg2.extras import RealDictCursor, Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sql_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_ADDRESS = '34.220.55.180'\n",
    "DBNAME = 'postgres'\n",
    "USER = 'postgres'\n",
    "PASSWORD = 'foobar1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Postgres Server with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to programmatically connect to and insert data into database:\n",
    "-  **con_cur_to_db**: returns both a connection and a cursor object for database\n",
    "-  **execute_query**: executes query directly to database, without having to create a cursor and connection each time\n",
    "-  **insert_entry_json**: inserts data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    ''' \n",
    "    Returns both a connection and a cursor object for your database\n",
    "    '''\n",
    "\n",
    "    con = pg2.connect(host=IP_ADDRESS, #allows you to navigate db\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    '''\n",
    "    Executes a query directly to a database, without having to create a cursor and connection each time. \n",
    "    '''\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection\n",
    "\n",
    "def insert_entry_json(data, tablename=None):\n",
    "    con, cur = con_cur_to_db()\n",
    "    for x in data:\n",
    "        cur.execute(f'INSERT INTO {tablename} (data) VALUES ({Json(x)});')\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define API keys and instantiate twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {\n",
    "    'consumer_key':        'WuBAkr5TGQmgadzpHmOeSzPWk',\n",
    "    'consumer_secret':     'pfim3bjV2X6ONw1Xf7qktrgLZ54gCZku7e2BcjT61Fz5SKCvUz',\n",
    "    'access_token_key':    '1080999232427909120-pWDWD3VwbiYwlfCIo05cKCLXmKNooH',\n",
    "    'access_token_secret': 'HYwBAbszupAT56B6giElUv2IVsNRBx5scB3LvdseFMOPP'\n",
    "}\n",
    "\n",
    "api = twitter.Api(consumer_key         =   twitter_keys['consumer_key'],\n",
    "                  consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "                  access_token_key     =   twitter_keys['access_token_key'],\n",
    "                  access_token_secret  =   twitter_keys['access_token_secret'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Fri Jan 04 01:27:55 +0000 2019\", \"default_profile\": true, \"default_profile_image\": true, \"geo_enabled\": true, \"id\": 1080999232427909120, \"id_str\": \"1080999232427909120\", \"lang\": \"en\", \"name\": \"connie\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_image_url_https\": \"https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"connie99418347\"}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect tweets and store into database:\n",
    "-  `geocode`: specify geolocation within which to search for tweets\n",
    "-  `terms`: terms to search by\n",
    "-  `result_type`: type of results returned (mixed, recent or popular)\n",
    "-  `since`: search for tweets since specified date\n",
    "-  `count`: number of results returned (100 max)\n",
    "-  `sql_db`: database to save tweets to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamTweets(term, geocode, since, count, sql_db='raw_tweets'):\n",
    "    for i in range(1,8):\n",
    "        year, month, day = since.split('-')\n",
    "        day = int(day)\n",
    "        day-=1\n",
    "        day = str(day).zfill(2)\n",
    "        date = year + month + day\n",
    "        after = datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        results = api.GetSearch(\n",
    "#             since = since,\n",
    "#             terms = ['jt', 'justin timberlake', 'jtimberlake', 'justin', 'timberlake', 'concert', 'show', 'mirror', 'cry me a river',\n",
    "#     'man of the woods', 'tour', 'music', 'PNC', 'welcome back', 'TN kids', 'tennessee kids']\n",
    "\n",
    "            term = term,\n",
    "            geocode = geocode,\n",
    "            return_json = True\n",
    "        )\n",
    "\n",
    "        insert_entry_json(data = results['statuses'], \n",
    "                          tablename = sql_db)\n",
    "        before = after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to have `streamTweets` on a loop to programmatically collect tweets:\n",
    "-  Repeat function 15 times, returning 100 (`count`) each time\n",
    "-  Pause for 40 seconds to avoid exceeding rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_repeater(term, geocode, since, repeats=15, count=100, sql_db='raw_tweets'):\n",
    "    for i in range(repeats):\n",
    "        since = since\n",
    "        \n",
    "        streamTweets(term, geocode, since, count, sql_db)\n",
    "        print(f'Loop {i+1} complete. Raw tweets pushed to {sql_db}.')\n",
    "        time.sleep(40)\n",
    "        \n",
    "    print('All tweets pulled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_list = [\n",
    "    ['malibu_ca', 'flash_flood/mudslide', '2019-01-06', '34.0249999', '-118.773830238'], \n",
    "    ['riverside_ca', 'mudslide', '2019-01-13', '33.9806', '-117.3755'], \n",
    "    ['orange_county_ca', 'flash_flood', '2019-01-14', '33.7175', '-117.8311'], \n",
    "    ['sandiego_county_ca', 'flash_flood', '2019-01-14', '33.7175', '-117.8311'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect most recent tweets:\n",
    "\n",
    "-  within 15 mile radius of all locations\n",
    "-  run function 100 times, collecting 700 tweets (1 week x 100 tweets) each time\n",
    "-  save into `raw_tweets` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_repeater(term='storm',\n",
    "               geocode='34.0249999,-118.773830238,15mi',\n",
    "               since='2019-01-06',\n",
    "               repeats=100, \n",
    "               count=100, \n",
    "               sql_db='raw_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from PostgresSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'text'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "\n",
    "df_text = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- retrieve text from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data#>'{place,bounding_box,coordinates}'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "\n",
    "df_geo = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- retrieve geo coordinates from tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.dropna(how = 'any', subset = ['?column?'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop tweets without coordinates from geo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "\n",
    "for tweet in df_geo['?column?']:\n",
    "    inside = tweet[0][1]\n",
    "    outside = tweet[0][3]\n",
    "    lat = (inside[0] + outside[0])/2\n",
    "    long = (inside[1] + outside[1])/2\n",
    "    latitude.append(lat)\n",
    "    longitude.append(long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- take the average of the box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo['lat'] = latitude\n",
    "df_geo['long'] = longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add latitude and longitude to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_text, df_geo[['lat', 'long']], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merge text dataframe and geo dataframe through the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop duplicate tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
