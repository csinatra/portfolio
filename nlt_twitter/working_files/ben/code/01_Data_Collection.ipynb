{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "-  [Configure Postgres Server with Docker](#Configure-Postgres-Server-with-Docker)\n",
    "-  [Application Token](#Application-Token)\n",
    "-  [Collect Tweets](#Collect-Tweets)\n",
    "-  [Retrieve Data from PostgreSQL Database](#Retrieve-Data-from-PostgreSQL-Database)\n",
    "-  [Save Data](#Save-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import json\n",
    "import time\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from psycopg2.extras import RealDictCursor, Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../sql_test.py\n",
    "%run ../twitter_credentials.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Postgres Server with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to programmatically connect to and insert data into database:\n",
    "-  **con_cur_to_db**: returns both a connection and a cursor object for database\n",
    "-  **execute_query**: executes query directly to database, without having to create a cursor and connection each time\n",
    "-  **insert_entry_json**: inserts data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    con = pg2.connect(host=IP_ADDRESS,\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection\n",
    "\n",
    "def insert_entry_json(data, tablename=None):\n",
    "    con, cur = con_cur_to_db()\n",
    "    for x in data:\n",
    "        cur.execute(f'INSERT INTO {tablename} (data) VALUES ({Json(x)});')\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table `raw_tweets` to save our collected data into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''CREATE TABLE raw_tweets\n",
    "(id SERIAL,\n",
    "data JSONB);'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_query(query, command=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define API keys and instantiate twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {\n",
    "    'consumer_key':        CONSUMER_KEY,\n",
    "    'consumer_secret':     CONSUMER_SECRET,\n",
    "    'access_token_key':    ACCESS_TOKEN,\n",
    "    'access_token_secret': ACCESS_TOKEN_SECRET\n",
    "}\n",
    "\n",
    "api = twitter.Api(consumer_key         =   twitter_keys['consumer_key'],\n",
    "                  consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "                  access_token_key     =   twitter_keys['access_token_key'],\n",
    "                  access_token_secret  =   twitter_keys['access_token_secret'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect tweets and store into database:\n",
    "-  `term`: term to search by\n",
    "-  `geocode`: specify geolocation within which to search for tweets\n",
    "-  `since`: search for tweets since specified date\n",
    "-  `count`: number of results returned (100 max)\n",
    "-  `sql_db`: database to save tweets to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamTweets(term, geocode, since, count, sql_db):\n",
    "    for i in range(1,8):\n",
    "        year, month, day = since.split('-')\n",
    "        day = int(day)\n",
    "        day-=1\n",
    "        day = str(day).zfill(2)\n",
    "        date = year + month + day\n",
    "        after = datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        results = api.GetSearch(\n",
    "            term = term,\n",
    "            geocode = geocode,\n",
    "            return_json = True\n",
    "        )\n",
    "\n",
    "        insert_entry_json(data = results['statuses'], \n",
    "                          tablename = sql_db)\n",
    "        before = after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to have `streamTweets` on a loop to programmatically collect tweets:\n",
    "-  Repeat function 15 times, returning 100 (`count`) each time\n",
    "-  Pause for 40 seconds to avoid exceeding rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_repeater(term, geocode, since, sql_db, repeats=15, count=100):\n",
    "    for i in range(repeats):\n",
    "        since = since\n",
    "        \n",
    "        streamTweets(term, geocode, since, count, sql_db)\n",
    "        print(f'Loop {i+1} complete. Raw tweets pushed to {sql_db}.')\n",
    "        time.sleep(40)\n",
    "        \n",
    "    print('All tweets pulled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect most recent tweets:\n",
    "-  that contains the term `storm` (terms were determined by natural disasters during time of search)\n",
    "-  within 15 mile radius of location\n",
    "-  starting from 2019-01-13\n",
    "-  run function 100 times, collecting 700 tweets (1 week x 100 tweets) each time\n",
    "-  save into `raw_tweets` database\n",
    "-  sample output is displayed \n",
    "\n",
    "We searched over two locations and used the following terms for each:\n",
    "\n",
    "|Location|Latitude|Longitude|Search Terms|Since Date|\n",
    "|---|---|---|---|---|\n",
    "|Malibu, CA|34.0249999|-118.773830238|flood, mudslide, landslide, rain, storm|2019-01-06|\n",
    "|Riverside, CA|33.9806|-117.3755|flood|2019-01-13|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 complete. Raw tweets pushed to raw_tweets.\n",
      "All tweets pulled.\n"
     ]
    }
   ],
   "source": [
    "tweet_repeater(term='storm',\n",
    "               geocode='33.9806,-117.3755,15mi',\n",
    "               since='2019-01-13',\n",
    "               repeats=100, \n",
    "               count=100,\n",
    "               sql_db='raw_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data from PostgreSQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT * to determine data structure and find information most relevant to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'psycopg2.extras.RealDictRow'>\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT * FROM raw_tweets;'''\n",
    "response = execute_query(query, dict_cur=True)\n",
    "print(type(response))\n",
    "print(type(response[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text (Tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is stored as a list of nested dictionaries. We want to retrieve the text itself (`text`), nested under `data` and put it in a dataframe (`df_text`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT data ->> 'text'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "df_text = pd.DataFrame(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geo-Coordinates\n",
    "We then want to retrieve the geo coordinates for each tweet in order to map their location and allocate resources there. This is stored in dataframe `df_geo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>?column?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[-118.794237, 34.125821], [-118.715023, 34.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[[[-118.794237, 34.125821], [-118.715023, 34.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[[[-118.794237, 34.125821], [-118.715023, 34.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[[[-118.668404, 33.704538], [-118.155409, 33.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ?column?\n",
       "3   [[[-118.794237, 34.125821], [-118.715023, 34.1...\n",
       "15  [[[-118.668404, 33.704538], [-118.155409, 33.7...\n",
       "26  [[[-118.794237, 34.125821], [-118.715023, 34.1...\n",
       "34  [[[-118.794237, 34.125821], [-118.715023, 34.1...\n",
       "43  [[[-118.668404, 33.704538], [-118.155409, 33.7..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"SELECT data#>'{place,bounding_box,coordinates}'\n",
    "FROM raw_tweets;\n",
    "\"\"\"\n",
    "response = execute_query(query, dict_cur=True)\n",
    "df_geo = pd.DataFrame(response).dropna()\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users that do not have location enabled will return `NaN`, so we'll drop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bounding box for the geo-fence is in a nested list. We key into the list and take the average left/right latitude and upper/lower longitude to approximate the location of a given tweet. These values are stored in the `lat` and `long` column, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "\n",
    "for tweet in df_geo['?column?']:\n",
    "    inside = tweet[0][1]\n",
    "    outside = tweet[0][3]\n",
    "    lat = (inside[0] + outside[0])/2\n",
    "    long = (inside[1] + outside[1])/2\n",
    "    latitude.append(lat)\n",
    "    longitude.append(long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then drop the nested list stored in `?column?`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geo.drop(columns=['?column?'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge our text and geo-coordinates data into one dataframe, `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_text, df_geo, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every twitter query returns a random subset of tweets containing the specified search term. We drop duplicates to ensure every tweet is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/raw_tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
