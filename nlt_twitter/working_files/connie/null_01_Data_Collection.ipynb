{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-twitter in /Users/connie/anaconda3/lib/python3.6/site-packages (3.5)\n",
      "Requirement already satisfied: future in /Users/connie/anaconda3/lib/python3.6/site-packages (from python-twitter) (0.17.1)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/connie/anaconda3/lib/python3.6/site-packages (from python-twitter) (1.0.0)\n",
      "Requirement already satisfied: requests in /Users/connie/anaconda3/lib/python3.6/site-packages (from python-twitter) (2.18.4)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests-oauthlib->python-twitter) (2.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/connie/anaconda3/lib/python3.6/site-packages (from requests->python-twitter) (2018.4.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /Users/connie/anaconda3/lib/python3.6/site-packages (2.7.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter \n",
    "import json\n",
    "import time\n",
    "import psycopg2 as pg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from psycopg2.extras import RealDictCursor, Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'sql_test.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run sql_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_ADDRESS = '34.222.246.54'\n",
    "DBNAME = 'postgres'\n",
    "USER = 'postgres'\n",
    "PASSWORD = 'foobar1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Postgres Server with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions to programmatically connect to and insert data into database:\n",
    "-  **con_cur_to_db**: returns both a connection and a cursor object for database\n",
    "-  **execute_query**: executes query directly to database, without having to create a cursor and connection each time\n",
    "-  **insert_entry_json**: inserts data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_db(dbname=DBNAME, dict_cur=None):\n",
    "    ''' \n",
    "    Returns both a connection and a cursor object for your database\n",
    "    '''\n",
    "\n",
    "    con = pg2.connect(host=IP_ADDRESS, #allows you to navigate db\n",
    "                  dbname=dbname,\n",
    "                  user=USER,\n",
    "                  password=PASSWORD)\n",
    "    if dict_cur:\n",
    "        cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    else:\n",
    "        cur = con.cursor()\n",
    "    return con, cur\n",
    "    \n",
    "def execute_query(query, dbname=DBNAME, dict_cur=None, command=False):\n",
    "    '''\n",
    "    Executes a query directly to a database, without having to create a cursor and connection each time. \n",
    "    '''\n",
    "    con, cur = con_cur_to_db(dbname, dict_cur)\n",
    "    cur.execute(f'{query}')\n",
    "    if not command:\n",
    "        data = cur.fetchall()\n",
    "        con.close()\n",
    "        return data\n",
    "    con.commit() #sends to server\n",
    "    con.close() #closes server connection\n",
    "\n",
    "def insert_entry_json(data, tablename=None):\n",
    "    con, cur = con_cur_to_db()\n",
    "    for x in data:\n",
    "        cur.execute(f'INSERT INTO {tablename} (data) VALUES ({Json(x)});')\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define API keys and instantiate twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = {\n",
    "    'consumer_key':        'WuBAkr5TGQmgadzpHmOeSzPWk',\n",
    "    'consumer_secret':     'pfim3bjV2X6ONw1Xf7qktrgLZ54gCZku7e2BcjT61Fz5SKCvUz',\n",
    "    'access_token_key':    '1080999232427909120-pWDWD3VwbiYwlfCIo05cKCLXmKNooH',\n",
    "    'access_token_secret': 'HYwBAbszupAT56B6giElUv2IVsNRBx5scB3LvdseFMOPP'\n",
    "}\n",
    "\n",
    "api = twitter.Api(consumer_key         =   twitter_keys['consumer_key'],\n",
    "                  consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "                  access_token_key     =   twitter_keys['access_token_key'],\n",
    "                  access_token_secret  =   twitter_keys['access_token_secret'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Fri Jan 04 01:27:55 +0000 2019\", \"default_profile\": true, \"default_profile_image\": true, \"id\": 1080999232427909120, \"id_str\": \"1080999232427909120\", \"lang\": \"en\", \"name\": \"connie\", \"profile_background_color\": \"F5F8FA\", \"profile_image_url\": \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_image_url_https\": \"https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\", \"profile_link_color\": \"1DA1F2\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"connie99418347\"}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Status(ID=1085044701500035072, ScreenName=Newwayofdoing, Created=Tue Jan 15 05:23:10 +0000 2019, Text='RT @1075rosebud1: Who benefits from Cubbie Station? A Chinese/Japanese conglomerate, certainly not our river systems. It comprises 96 hecta…'),\n",
       " Status(ID=1085044679270232064, ScreenName=VeritasinCali, Created=Tue Jan 15 05:23:05 +0000 2019, Text='RT @MRCAParks: Our partners at @SantaMonicaMtns are unable to monitor conditions at Paramount Ranch, Palo Comado &amp; Cheeseboro Cyns, Rancho…'),\n",
       " Status(ID=1085044655497113600, ScreenName=rangertx08008, Created=Tue Jan 15 05:22:59 +0000 2019, Text=\"RT @LisaMei62: Liddle Adam appears to be nervous about some REAL videos that might surface. [They] will claim they are fake. It won't save…\"),\n",
       " Status(ID=1085044644776476672, ScreenName=gnimie, Created=Tue Jan 15 05:22:57 +0000 2019, Text='RT @LauraAJarrett: Some news from @Arianedevogue - that controversial June 2018 Barr memo on obstruction went to WH lawyer Emmet Flood, SG…'),\n",
       " Status(ID=1085044627445403648, ScreenName=dwiz882, Created=Tue Jan 15 05:22:52 +0000 2019, Text='RT @JILLRESONTOC: AMLC papasok sa probe ng Flood control scam na binintang ni Andaya kay Diokno kung mayroon  pending na kaso tungkol sa ak…'),\n",
       " Status(ID=1085044620315279360, ScreenName=anak_ng_masa, Created=Tue Jan 15 05:22:51 +0000 2019, Text='LOOK: \\n\\nSenator Jinggoy Estrada visits the LGU of Malilipot, Albay for relief operations for the landslide affected… https://t.co/7UPgppTkyE'),\n",
       " Status(ID=1085044573552791552, ScreenName=ColleenCobb17, Created=Tue Jan 15 05:22:40 +0000 2019, Text='RT @Condor_Law: Over 30,000 Teachers Walk Out - Demand Higher Pay, Smaller Class Sizes\\n\\nIf they think 40 kids/classroom is too many, wait u…'),\n",
       " Status(ID=1085044481659944960, ScreenName=SuzaSusza, Created=Tue Jan 15 05:22:18 +0000 2019, Text='RT @ouchinagirl: FLIP/FLOOD RED❣️ #BuildTheWill #FundTheWall #DemocratShutdown #StopTheTrillionDollarTransfer #WeThePeopleStandWithTrump ht…'),\n",
       " Status(ID=1085044432599203842, ScreenName=Bigmommajanjan, Created=Tue Jan 15 05:22:06 +0000 2019, Text='The Folklorist: The Great Boston Molasses Flood (Official) https://t.co/K8LlWZNq2E via @YouTube @BostonMagazine'),\n",
       " Status(ID=1085044420594982912, ScreenName=KUSINews, Created=Tue Jan 15 05:22:03 +0000 2019, Text='Heading to Fashion or Mission Valley this week? Flood teams are on high alert in the area during these rainy condit… https://t.co/EFUTmO37Yv'),\n",
       " Status(ID=1085044416291786758, ScreenName=sameehwantPeace, Created=Tue Jan 15 05:22:02 +0000 2019, Text='RT @RRPMalayil: Mr Disaster @narendramodi refused to accept foreign aid during the catastrophic flood that drowned all 14 districts of d st…'),\n",
       " Status(ID=1085044356833263616, ScreenName=etdcampbell, Created=Tue Jan 15 05:21:48 +0000 2019, Text=\"RT @LisaMei62: Liddle Adam appears to be nervous about some REAL videos that might surface. [They] will claim they are fake. It won't save…\"),\n",
       " Status(ID=1085044347081347072, ScreenName=thegrugq, Created=Tue Jan 15 05:21:46 +0000 2019, Text='@CipheredYT I’m probably suffering from a lack of imagination here, but I don’t see how it’ll be a huge game change… https://t.co/yJ7SgfLrxQ'),\n",
       " Status(ID=1085044339678502913, ScreenName=okramesh, Created=Tue Jan 15 05:21:44 +0000 2019, Text='RT @1075rosebud1: Who benefits from Cubbie Station? A Chinese/Japanese conglomerate, certainly not our river systems. It comprises 96 hecta…'),\n",
       " Status(ID=1085044321324154880, ScreenName=mickijanus, Created=Tue Jan 15 05:21:40 +0000 2019, Text='RT @hrtablaze: THIS !!!!!! THIS RIGHT HERE is why Democrats want to flood our country with ill Legals !!!!!! They get more seats in Congres…')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.GetSearch(raw_query='q=mudslide%2C%20OR%20flood%2C%20OR%20landslide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'twitter.api' has no attribute 'GetSearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-65817541b42b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = twitter.api.GetSearch(\n\u001b[0m\u001b[1;32m      2\u001b[0m     raw_query='q=flash%20OR%20flood%20OR%20mudslide%20OR%20landslide%20near%3A\"Malibu%2C%20CA\"%20within%3A15mi')\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'twitter.api' has no attribute 'GetSearch'"
     ]
    }
   ],
   "source": [
    "results = twitter.api.GetSearch(\n",
    "    raw_query='q=flash%20OR%20flood%20OR%20mudslide%20OR%20landslide%20near%3A\"Malibu%2C%20CA\"%20within%3A15mi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect tweets and store into database:\n",
    "-  `geocode`: specify geolocation within which to search for tweets\n",
    "-  `terms`: terms to search by\n",
    "-  `result_type`: type of results returned (mixed, recent or popular)\n",
    "-  `since`: search for tweets since specified date\n",
    "-  `count`: number of results returned (100 max)\n",
    "-  `sql_db`: database to save tweets to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamTweets(geocode, result_type, since, count, sql_db='raw_tweets'):\n",
    "    for i in range(1,8):\n",
    "        year, month, day = since.split('-')\n",
    "        day = int(day)\n",
    "        day-=1\n",
    "        day = str(day).zfill(2)\n",
    "        date = year + month + day\n",
    "        after = datetime.strptime(date, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "        \n",
    "        results = api.GetSearch(\n",
    "            since = since,\n",
    "#             terms = ['jt', 'justin timberlake', 'jtimberlake', 'justin', 'timberlake', 'concert', 'show', 'mirror', 'cry me a river',\n",
    "#     'man of the woods', 'tour', 'music', 'PNC', 'welcome back', 'TN kids', 'tennessee kids']\n",
    "            geocode = geocode,\n",
    "            result_type = result_type,\n",
    "            return_json = True\n",
    "        )\n",
    "\n",
    "        insert_entry_json(data = results['statuses'], \n",
    "                          tablename = sql_db)\n",
    "        before = after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to have `streamTweets` on a loop to programmatically collect tweets:\n",
    "-  Repeat function 15 times, returning 100 (`count`) each time\n",
    "-  Pause for 40 seconds to avoid exceeding rate limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_repeater(geocode, result_type, since, repeats=15, count=100, sql_db='raw_tweets'):\n",
    "    for i in range(repeats):\n",
    "        since = since\n",
    "        \n",
    "        streamTweets(geocode, result_type, since, count, sql_db)\n",
    "        print(f'Loop {i+1} complete. Raw tweets pushed to {sql_db}.')\n",
    "        time.sleep(40)\n",
    "        \n",
    "    print('All tweets pulled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect most recent tweets:\n",
    "\n",
    "|Location|Latitude|Longitude|Start Date|\n",
    "|---|---|---|---|\n",
    "|Charlotte, NC|35.227085|-80.843124|2019-01-08|\n",
    "|Atlanta, GA|33.753746|-84.386330|2019-01-10|\n",
    "|Memphis, TN|35.14953|-90.04898|2019-01-12|\n",
    "|New Orleans, LA|29.951065|-90.071533|2019-01-15|\n",
    "|Little Rock, AR|34.746483|-92.289597|2019-01-17|\n",
    "\n",
    "-  within 10 mile radius of all locations\n",
    "-  run function 100 times, collecting 700 tweets (1 week x 100 tweets) each time\n",
    "-  save into `raw_tweets` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 1 complete. Raw tweets pushed to raw_tweets.\n",
      "Loop 2 complete. Raw tweets pushed to raw_tweets.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e527a26e49de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                sql_db='raw_tweets')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-09dea3fcdf94>\u001b[0m in \u001b[0;36mtweet_repeater\u001b[0;34m(geocode, result_type, since, repeats, count, sql_db)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msince\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mstreamTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msince\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loop {i+1} complete. Raw tweets pushed to {sql_db}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-24473fbac599>\u001b[0m in \u001b[0;36mstreamTweets\u001b[0;34m(geocode, result_type, since, count, sql_db)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         insert_entry_json(data = results['statuses'], \n\u001b[0;32m---> 20\u001b[0;31m                           tablename = sql_db)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mbefore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4672c78eb29f>\u001b[0m in \u001b[0;36minsert_entry_json\u001b[0;34m(data, tablename)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcon_cur_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'INSERT INTO {tablename} (data) VALUES ({Json(x)});'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/encodings/utf_8.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tweet_repeater(geocode='35.227085,-80.843124,10mi', \n",
    "               result_type='recent',\n",
    "               since='2019-01-08',\n",
    "               repeats=100, \n",
    "               count=100, \n",
    "               sql_db='raw_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
