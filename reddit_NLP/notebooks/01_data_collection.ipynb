{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK 01: DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I will collect posts from the sub-reddits r/conservative and r/libertarian to identify terminology commonly used to self-identify within each community. Because the two communities share considerable ideological overlap, it's my hope that this project delivers interesting insights into how each group views itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the Pushshift API to build a corpus of text data that I will parse by Natural Language Processing (NLP) and then model with an optimized classification algorithm. Text will be pulled from comment threads as many posts contain only images in the body. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, csv, json, re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the base query syntax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the query url to the pushshift api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the parameters for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'searchType':'submission',\n",
    "          'subreddit':'conservative,libertarian',\n",
    "          'sort':'desc',\n",
    "          'size':10,\n",
    "#           'before':,\n",
    "#           'after':,\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the url to make sure the query terms are correct and the server is responsive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The status code returned from the server is 200, meaning the query was accepted and there aren't any connection issues. Checking length of the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response.json()['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length is 10, as expected. Assessing the file structure for keys of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keys of interest are:\n",
    "- author\n",
    "- body\n",
    "- created_utc\n",
    "- link_id\n",
    "- parent_id\n",
    "- permalink\n",
    "- subreddit\n",
    "- subreddit_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['author',\n",
    "            'body',\n",
    "            'subreddit',\n",
    "            'subreddit_id',\n",
    "            'created_utc',\n",
    "            'retrieved_on',\n",
    "            'link_id',\n",
    "            'parent_id',\n",
    "            'permalink',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Querying Reddit and saving raw data in .json format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a function for creating a logfile and formatting file names with a unique timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filename_format_log(file_path, \n",
    "                        logfile = '../assets/file_log.txt', \n",
    "                        now = round(time.time()), \n",
    "                        file_description = None): \n",
    "   \n",
    "    try:\n",
    "        ext = re.search('(?<!^)(?<!\\.)\\.(?!\\.)', file_path).start() \n",
    "    except:\n",
    "        raise NameError('Please enter a relative path with a file extension.') \n",
    "    \n",
    "    stamp = re.search('(?<!^)(?<!\\.)[a-z]+_[a-z]+(?=\\.)', file_path).start()\n",
    "    formatted_name = f'{file_path[:stamp]}{now}_{file_path[stamp:]}'  \n",
    "    if not file_description:\n",
    "        file_description = f'Pull: {time.asctime(time.gmtime(now))}'\n",
    "    with open(logfile, 'a+') as f:\n",
    "        f.write(f'{formatted_name}: {file_description}\\n')\n",
    "    return formatted_name, now, file_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a function for collecting comments and parsing into a dataframe with the features of interest, saving out the raw data for each pull. Request loop inspired: [(Source)](https://www.reddit.com/r/pushshift/comments/89pxra/pushshift_api_with_large_amounts_of_data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_query(subreddits, n_samples=1500, searchType='comment', before=None, after=None):\n",
    "    url = f'https://api.pushshift.io/reddit/search/'\n",
    "    last_comment = round(time.time())\n",
    "    comment_list = []\n",
    "    \n",
    "    run = 1\n",
    "    while len(comment_list) < n_samples:\n",
    "        \n",
    "        try:\n",
    "            print(f'Starting query {run}')\n",
    "            \n",
    "            params = {'searchType':searchType,\n",
    "              'subreddit':subreddits,\n",
    "              'sort':'desc',\n",
    "              'size':1500,\n",
    "              'before':last_comment-1,\n",
    "              'after':after,\n",
    "             }\n",
    "                \n",
    "            response = requests.get(url, params = params)\n",
    "            posts = response.json()['data']\n",
    "            \n",
    "            if len(posts) == 0:\n",
    "                last_comment = last_comment\n",
    "            else:\n",
    "                last_comment = posts[-1]['created_utc']\n",
    "                comment_list.extend(posts)\n",
    "                timestamp = posts[-1]['created_utc']\n",
    "                time.sleep(1) \n",
    "                run += 1\n",
    "        except:\n",
    "            if response.status_code != 200:\n",
    "                return f'Check status. Error code: {response.status_code}'\n",
    "            else:\n",
    "                return 'Error. Pull not completed.'\n",
    "    \n",
    "    formatted_name, now, file_description = filename_format_log(file_path =f'../data/raw_{searchType}s.json', now=timestamp)\n",
    "    with open(formatted_name, 'w+') as f:\n",
    "        json.dump(comment_list, f)\n",
    "    \n",
    "    print(f'Saved and completed query and returned {len(comment_list)} {searchType}s.')\n",
    "    print(f'Reddit text is ready for processing.')\n",
    "    return print(f'Last timestamp was {timestamp}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the query function to collect 100k comments from the conservative subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_query(subreddits='conservative',\n",
    "             n_samples=100000,\n",
    "             searchType='comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the query function to collect 100k comments from the libertarian subreddit beginning at the same time as the conservative comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_query(subreddits='libertarian',\n",
    "             n_samples=100000,\n",
    "             before=1544922850,\n",
    "             searchType='comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking final timestamps to understand the time over which the comments were collected. While our data is sensative to current events, in an effort to preserve class balance and minimize bootstrapping or other class rebalancing methods we will assume that overall syntatical choices are consistent over our timefreame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sat Dec  1 03:15:34 2018'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=1543634134\n",
    "time.asctime(time.gmtime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fri Nov 30 20:59:47 2018'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=1543611587\n",
    "time.asctime(time.gmtime(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features of interest and converting into a DataFrame:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the conservative samples as a .json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/1541516104_raw_comments.json', 'r') as f:\n",
    "    cons_sample_list = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking file length to ensure complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cons_sample_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the structure of the first entry to compare across both datasets and ensure the correct samples were collected from the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'rojindahar',\n",
       " 'author_flair_background_color': None,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'author_flair_template_id': None,\n",
       " 'author_flair_text': None,\n",
       " 'author_flair_text_color': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'author_fullname': 't2_26vla1s8',\n",
       " 'author_patreon_flair': False,\n",
       " 'body': 'He already does Ketamine, 58 second mark: https://youtu.be/Pmrp3JVFrb8',\n",
       " 'created_utc': 1544922841,\n",
       " 'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       " 'id': 'ebvq8at',\n",
       " 'link_id': 't3_a6krv2',\n",
       " 'no_follow': True,\n",
       " 'parent_id': 't3_a6krv2',\n",
       " 'permalink': '/r/Conservative/comments/a6krv2/10yearold_boy_dances_on_stage_for_money_at_adult/ebvq8at/',\n",
       " 'retrieved_on': 1544922850,\n",
       " 'score': 1,\n",
       " 'send_replies': True,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'Conservative',\n",
       " 'subreddit_id': 't5_2qh6p'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_sample_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating the import and file review steps for the libertarian samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/1543468607_raw_comments.json', 'r') as f:\n",
    "    libr_sample_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(libr_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'spacefish3',\n",
       " 'author_flair_background_color': None,\n",
       " 'author_flair_css_class': None,\n",
       " 'author_flair_richtext': [],\n",
       " 'author_flair_template_id': None,\n",
       " 'author_flair_text': None,\n",
       " 'author_flair_text_color': None,\n",
       " 'author_flair_type': 'text',\n",
       " 'author_fullname': 't2_j15fb',\n",
       " 'author_patreon_flair': False,\n",
       " 'body': '\"Workers\\' collective ownership of capital\" never implies that a state must exist.',\n",
       " 'created_utc': 1544931627,\n",
       " 'gildings': {'gid_1': 0, 'gid_2': 0, 'gid_3': 0},\n",
       " 'id': 'ebw07aq',\n",
       " 'link_id': 't3_a21e9n',\n",
       " 'no_follow': True,\n",
       " 'parent_id': 't1_eax5n3o',\n",
       " 'permalink': '/r/Libertarian/comments/a21e9n/the_admins_lied_our_mods_did_not_approve_the/ebw07aq/',\n",
       " 'retrieved_on': 1544931628,\n",
       " 'score': 1,\n",
       " 'send_replies': True,\n",
       " 'stickied': False,\n",
       " 'subreddit': 'Libertarian',\n",
       " 'subreddit_id': 't5_2qh63'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libr_sample_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing the json file into a dataframe containing the features of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_parse(sample):\n",
    "    \n",
    "    col_list = ['author',\n",
    "                'body',\n",
    "                'subreddit',\n",
    "                'subreddit_id',\n",
    "                'created_utc',\n",
    "                'link_id',\n",
    "                'parent_id',\n",
    "                'permalink',\n",
    "                ]\n",
    "    \n",
    "    comments_df = pd.DataFrame(sample)\n",
    "    comments_df = comments_df[col_list]\n",
    "    \n",
    "    comments_df.rename(columns={'subreddit':'libertarian'}, inplace=True)\n",
    "    comments_df['libertarian'] = comments_df['libertarian'].map({'Conservative':0, 'Libertarian':1})\n",
    "    \n",
    "    col_order = ['author',\n",
    "                 'body',\n",
    "                 'libertarian',\n",
    "                 'created_utc',\n",
    "                 'subreddit_id',\n",
    "                 'parent_id',\n",
    "                 'link_id',\n",
    "                 'permalink',\n",
    "                ]\n",
    "\n",
    "    return comments_df[col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the shape of the dataframe to ensure correct transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_comments = reddit_parse(cons_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_comments_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape corresponds with expected values. Reviewing the head of the dataframe to ensure data was correctly labeled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>libertarian</th>\n",
       "      <th>created_on</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rojindahar</td>\n",
       "      <td>He already does Ketamine, 58 second mark: http...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 16 01:14:01 2018</td>\n",
       "      <td>Sun Dec 16 01:14:10 2018</td>\n",
       "      <td>1544922841</td>\n",
       "      <td>t5_2qh6p</td>\n",
       "      <td>t3_a6krv2</td>\n",
       "      <td>t3_a6krv2</td>\n",
       "      <td>/r/Conservative/comments/a6krv2/10yearold_boy_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 16 01:13:28 2018</td>\n",
       "      <td>Sun Dec 16 01:13:39 2018</td>\n",
       "      <td>1544922808</td>\n",
       "      <td>t5_2qh6p</td>\n",
       "      <td>t1_ebvclrz</td>\n",
       "      <td>t3_a6icni</td>\n",
       "      <td>/r/Conservative/comments/a6icni/to_guarantee_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 16 01:13:15 2018</td>\n",
       "      <td>Sun Dec 16 01:13:26 2018</td>\n",
       "      <td>1544922795</td>\n",
       "      <td>t5_2qh6p</td>\n",
       "      <td>t1_ebvg44o</td>\n",
       "      <td>t3_a6icni</td>\n",
       "      <td>/r/Conservative/comments/a6icni/to_guarantee_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leadrain86</td>\n",
       "      <td>Actually that is quite the opposite. Conservat...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 16 01:13:09 2018</td>\n",
       "      <td>Sun Dec 16 01:13:20 2018</td>\n",
       "      <td>1544922789</td>\n",
       "      <td>t5_2qh6p</td>\n",
       "      <td>t1_ebvhrk2</td>\n",
       "      <td>t3_a6a7h7</td>\n",
       "      <td>/r/Conservative/comments/a6a7h7/one_year_ago_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>Sun Dec 16 01:11:49 2018</td>\n",
       "      <td>Sun Dec 16 01:12:00 2018</td>\n",
       "      <td>1544922709</td>\n",
       "      <td>t5_2qh6p</td>\n",
       "      <td>t3_a4llsj</td>\n",
       "      <td>t3_a4llsj</td>\n",
       "      <td>/r/Conservative/comments/a4llsj/keep_tyrants_l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author                                               body  libertarian  \\\n",
       "0  rojindahar  He already does Ketamine, 58 second mark: http...            0   \n",
       "1   [deleted]                                          [removed]            0   \n",
       "2   [deleted]                                          [removed]            0   \n",
       "3  leadrain86  Actually that is quite the opposite. Conservat...            0   \n",
       "4   [deleted]                                          [removed]            0   \n",
       "\n",
       "                 created_on              retrieved_on  created_utc  \\\n",
       "0  Sun Dec 16 01:14:01 2018  Sun Dec 16 01:14:10 2018   1544922841   \n",
       "1  Sun Dec 16 01:13:28 2018  Sun Dec 16 01:13:39 2018   1544922808   \n",
       "2  Sun Dec 16 01:13:15 2018  Sun Dec 16 01:13:26 2018   1544922795   \n",
       "3  Sun Dec 16 01:13:09 2018  Sun Dec 16 01:13:20 2018   1544922789   \n",
       "4  Sun Dec 16 01:11:49 2018  Sun Dec 16 01:12:00 2018   1544922709   \n",
       "\n",
       "  subreddit_id   parent_id    link_id  \\\n",
       "0     t5_2qh6p   t3_a6krv2  t3_a6krv2   \n",
       "1     t5_2qh6p  t1_ebvclrz  t3_a6icni   \n",
       "2     t5_2qh6p  t1_ebvg44o  t3_a6icni   \n",
       "3     t5_2qh6p  t1_ebvhrk2  t3_a6a7h7   \n",
       "4     t5_2qh6p   t3_a4llsj  t3_a4llsj   \n",
       "\n",
       "                                           permalink  \n",
       "0  /r/Conservative/comments/a6krv2/10yearold_boy_...  \n",
       "1  /r/Conservative/comments/a6icni/to_guarantee_a...  \n",
       "2  /r/Conservative/comments/a6icni/to_guarantee_a...  \n",
       "3  /r/Conservative/comments/a6a7h7/one_year_ago_t...  \n",
       "4  /r/Conservative/comments/a4llsj/keep_tyrants_l...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_comments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_comments_df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates were found, so shape is the same as the original dataframe. Repeating these steps for the libertarian dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libr_comments = reddit_parse(libr_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libr_comments_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape output corresponds to expected values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>libertarian</th>\n",
       "      <th>created_on</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spacefish3</td>\n",
       "      <td>\"Workers' collective ownership of capital\" nev...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Dec 16 03:40:27 2018</td>\n",
       "      <td>Sun Dec 16 03:40:28 2018</td>\n",
       "      <td>1544931627</td>\n",
       "      <td>t5_2qh63</td>\n",
       "      <td>t1_eax5n3o</td>\n",
       "      <td>t3_a21e9n</td>\n",
       "      <td>/r/Libertarian/comments/a21e9n/the_admins_lied...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EatsPandas</td>\n",
       "      <td>hmmmmmmm interesting</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Dec 16 03:40:20 2018</td>\n",
       "      <td>Sun Dec 16 03:40:21 2018</td>\n",
       "      <td>1544931620</td>\n",
       "      <td>t5_2qh63</td>\n",
       "      <td>t3_a6lw8o</td>\n",
       "      <td>t3_a6lw8o</td>\n",
       "      <td>/r/Libertarian/comments/a6lw8o/libertarianism_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KruglorTalks</td>\n",
       "      <td>To be fair, credit to Cratchit just for litera...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Dec 16 03:40:05 2018</td>\n",
       "      <td>Sun Dec 16 03:40:07 2018</td>\n",
       "      <td>1544931605</td>\n",
       "      <td>t5_2qh63</td>\n",
       "      <td>t3_a6k2kt</td>\n",
       "      <td>t3_a6k2kt</td>\n",
       "      <td>/r/Libertarian/comments/a6k2kt/scroogedidnothi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Itl_chi_15</td>\n",
       "      <td>Game show hosts, they’re are truly the worst. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Dec 16 03:39:53 2018</td>\n",
       "      <td>Sun Dec 16 03:39:54 2018</td>\n",
       "      <td>1544931593</td>\n",
       "      <td>t5_2qh63</td>\n",
       "      <td>t3_a686wz</td>\n",
       "      <td>t3_a686wz</td>\n",
       "      <td>/r/Libertarian/comments/a686wz/not_every_actor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seabreezeintheclouds</td>\n",
       "      <td>I think the better explanation is who are the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun Dec 16 03:39:48 2018</td>\n",
       "      <td>Sun Dec 16 03:39:49 2018</td>\n",
       "      <td>1544931588</td>\n",
       "      <td>t5_2qh63</td>\n",
       "      <td>t3_a6jrtf</td>\n",
       "      <td>t3_a6jrtf</td>\n",
       "      <td>/r/Libertarian/comments/a6jrtf/the_most_libert...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                               body  \\\n",
       "0            spacefish3  \"Workers' collective ownership of capital\" nev...   \n",
       "1            EatsPandas                               hmmmmmmm interesting   \n",
       "2          KruglorTalks  To be fair, credit to Cratchit just for litera...   \n",
       "3            Itl_chi_15  Game show hosts, they’re are truly the worst. ...   \n",
       "4  seabreezeintheclouds  I think the better explanation is who are the ...   \n",
       "\n",
       "   libertarian                created_on              retrieved_on  \\\n",
       "0            1  Sun Dec 16 03:40:27 2018  Sun Dec 16 03:40:28 2018   \n",
       "1            1  Sun Dec 16 03:40:20 2018  Sun Dec 16 03:40:21 2018   \n",
       "2            1  Sun Dec 16 03:40:05 2018  Sun Dec 16 03:40:07 2018   \n",
       "3            1  Sun Dec 16 03:39:53 2018  Sun Dec 16 03:39:54 2018   \n",
       "4            1  Sun Dec 16 03:39:48 2018  Sun Dec 16 03:39:49 2018   \n",
       "\n",
       "   created_utc subreddit_id   parent_id    link_id  \\\n",
       "0   1544931627     t5_2qh63  t1_eax5n3o  t3_a21e9n   \n",
       "1   1544931620     t5_2qh63   t3_a6lw8o  t3_a6lw8o   \n",
       "2   1544931605     t5_2qh63   t3_a6k2kt  t3_a6k2kt   \n",
       "3   1544931593     t5_2qh63   t3_a686wz  t3_a686wz   \n",
       "4   1544931588     t5_2qh63   t3_a6jrtf  t3_a6jrtf   \n",
       "\n",
       "                                           permalink  \n",
       "0  /r/Libertarian/comments/a21e9n/the_admins_lied...  \n",
       "1  /r/Libertarian/comments/a6lw8o/libertarianism_...  \n",
       "2  /r/Libertarian/comments/a6k2kt/scroogedidnothi...  \n",
       "3  /r/Libertarian/comments/a686wz/not_every_actor...  \n",
       "4  /r/Libertarian/comments/a6jrtf/the_most_libert...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libr_comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libr_comments_df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates found in this dataset. Since both dataframes have aligning features we will merge to create our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.concat([cons_comments_df, libr_comments_df],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the structure of the combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'body', 'libertarian', 'created_on', 'retrieved_on',\n",
       "       'created_utc', 'subreddit_id', 'parent_id', 'link_id', 'permalink'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting samples in chronilogical order and resetting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.sort_values(by=['created_utc'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the datatypes and checking for any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 10 columns):\n",
      "author          200000 non-null object\n",
      "body            200000 non-null object\n",
      "libertarian     200000 non-null int64\n",
      "created_on      200000 non-null object\n",
      "retrieved_on    200000 non-null object\n",
      "created_utc     200000 non-null int64\n",
      "subreddit_id    200000 non-null object\n",
      "parent_id       200000 non-null object\n",
      "link_id         200000 non-null object\n",
      "permalink       200000 non-null object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 15.3+ MB\n"
     ]
    }
   ],
   "source": [
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author          0\n",
       "body            0\n",
       "libertarian     0\n",
       "created_utc     0\n",
       "subreddit_id    0\n",
       "parent_id       0\n",
       "link_id         0\n",
       "permalink       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring balanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    100000\n",
       "0    100000\n",
       "Name: libertarian, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df['libertarian'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing any newline, carrage reuturns, or long whitespace elements with a single whitespace character to prevent any errors when saving out / reading in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df.body.map(lambda x :re.sub('\\s+', ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving out comments_df for Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving out the combined dataframe as a csv for preprocessing in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_name, now, file_description = filename_format_log(file_path ='../assets/comments_df.csv')\n",
    "comments_df.to_csv(formatted_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUE TO NOTEBOOK 02: PREPROCESSING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
