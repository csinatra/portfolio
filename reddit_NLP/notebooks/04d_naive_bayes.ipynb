{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # NOTEBOOK 04d: MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes is a generalized Bayesian classification model that is suited to large feature spaces. Typically used with discrete features, this model is also commonly used with Tfidf vectorized text data. As the name suggests, naive Bayes operates on the fundamental assumption that the independant variables are independant to reduce the complexity that stems from the conditional probabilities required for modeling dependant variables. Though we know this is contrary to the true nature of our data, this model still produces surprisingly accurate predictions for the simplicity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1544820504_comments_df.csv     1545277666_y_test.csv\n",
      "1544843302_comments_df.csv     1545277666_y_train.csv\n",
      "1544988010_comments_df.csv     1545285057_tfidf_col.csv\n",
      "1545241316_clean_target.csv    1545336727_SVD_col.csv\n",
      "1545241316_clean_text.csv      1545336727_XtestSVD_coo.npz\n",
      "1545249401_cvec_coo.npz        1545336727_XtestSVD_raw.csv\n",
      "1545249401_cvec_coo_col.csv    1545336727_XtrainSVD_coo.npz\n",
      "1545254581_clean_text.csv      1545336727_XtrainSVD_raw.csv\n",
      "1545266972_clean_text.csv      cvec_1545266972_coo_col.csv\n",
      "1545266972_cvec_coo.npz        file_log.txt\n",
      "1545266972_tfidf_coo.npz       test_1545277666_tfidf_coo.npz\n",
      "1545272821_eda_words.csv       tfidf_1545266972_coo_col.csv\n",
      "1545277666_tfidf_col.csv       train_1545277666_tfidf_coo.npz\n"
     ]
    }
   ],
   "source": [
    "!ls '../assets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Tfidf vectorized training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_csv('../assets/1545277666_tfidf_col.csv', na_filter=False, header=None)\n",
    "cols = np.array(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf_coo=sparse.load_npz('../assets/train_1545277666_tfidf_coo.npz')\n",
    "X_train_tfidf = pd.SparseDataFrame(X_train_tfidf_coo, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf_coo=sparse.load_npz('../assets/test_1545277666_tfidf_coo.npz')\n",
    "X_test_tfidf = pd.SparseDataFrame(X_test_tfidf_coo, columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling null values for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf.fillna(0, inplace=True)\n",
    "X_test_tfidf.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('../assets/1545277666_y_train.csv', header=None)\n",
    "y_test = pd.read_csv('../assets/1545277666_y_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the target data into a flattened 1-d array for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the Multinomial Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nb.fit(X_train_tfidf, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the model on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7434105765245653"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our fitted model predicted with 74.3% accuracy on our training data. This is to be compared against our baseline accuracy of 53.9%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7235188901492017"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation dataset was scored with 72.3% accuracy, slightly below the training score. This suggest that the model may be slightly overfit, though this could be within a reasonable marge of error. Overall, this is a very good score considering the simplicity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = pd.DataFrame(model.predict_proba(X_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reloading the original clean dataframe to connect the predicted probabilities to the sample text.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cb821d0f0138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../assets/1545272821_eda_words.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../assets/1545272821_eda_words.csv', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_test[(pred_probas[:1] >.7) & (y_test !=1)].index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the predicted probabilites, we see many of our observations either had wide margins or were very closely split with a margin less than 10%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fitted model to predict on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a confusion matrix to review the individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 13708\n",
      "False Positives: 7441\n",
      "False Negatives: 5234\n",
      "True Positives: 19461\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type I error rate (16%) was much higher than the type II error (11%), though in this case we don't necessarily consider one type of misclassification better or worse than than the other. For our purposes, we can consider them equivalent, however if we felt strongly that we err on the side of type II error we can decrease the sensitivity. Likewise, if our priority was aggressive screening of topical/syntatical variation we could increase the sensitivity at the expense of increasing the type I error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
